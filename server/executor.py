# executor.py
import sys
import os
import requests
import json
from server.vlm_handler import generate_caption
# Ensure project root is in path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from server.scripts.tools_main import run_tool

MCP_SERVER_URL = "http://localhost:9000/mcp/execute"
def execute_task(task: dict):
    task_type = task.get("type")

    if task_type == "image_caption":
        image_path = task.get("image_path")
        return generate_caption(image_path)

def run_executor(user_task):
    print(f"\n[EXECUTOR] Sending task: {user_task}")
    response = requests.post(MCP_SERVER_URL, json={"task": user_task})

    if response.status_code != 200:
        print(f"[ERROR] MCP server returned {response.status_code}: {response.text}")
        return

    try:
        task_plan = response.json()
        print(f"\n[PLAN RECEIVED] Task: {task_plan['task']}\n")

        # Store outputs from previous tools for chaining
        generated_outputs = {}

        for subtask in task_plan["subtasks"]:
            step = subtask["step"]
            description = subtask["description"]
            agent = subtask["agent"]
            tool = subtask["tool"]

            print(f"Step {step}: {description} (Agent: {agent}, Tool: {tool})")

            # Add original task context
            subtask["original_task_text"] = user_task

            # Inject generated email content if sending email
            if tool == "email_sender" and "text_generation" in generated_outputs:
                subtask["email_content"] = generated_outputs["text_generation"]

            # Execute the tool
            result = run_tool(tool, context=subtask)

            # Save LLM output for chaining (text_generation output)
            if tool == "text_generation":
                if isinstance(result, dict) and "text" in result:
                    generated_outputs["text_generation"] = result["text"]
                elif isinstance(result, str):
                    generated_outputs["text_generation"] = result

            if agent == "LLM":
                print(f"    => Generated by LLM tool: {result}")
            else:
                print(f"    => Tool result: {result}")

    except Exception as e:
        print(f"[ERROR] Failed to parse or execute task plan: {e}")
        print("Raw response:", response.text)
if __name__ == "__main__":
    user_input = input("Enter your high-level task: ")
    run_executor(user_input)

# executor.py
# import requests
# import json
# import uuid
# import logging
# import sys
# import os

# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# from server.scripts.tools_main import run_tool

# MCP_SERVER_URL = "http://localhost:9000/mcp/execute"
# WEBAGENT_URL = "http://localhost:8931/mcp"
# SESSION_ID = "3b5d8bb1-8016-46e3-a83f-057bc495d3a9"  # Reuse for consistent session


# def run_executor(user_task):
#     print(f"\n[EXECUTOR] Sending task: {user_task}")

#     # Initialize WebAgent before any subtasks


#     response = requests.post(MCP_SERVER_URL, json={"task": user_task})
#     if response.status_code != 200:
#         print(f"[ERROR] MCP server returned {response.status_code}: {response.text}")
#         return

#     try:
#         task_plan = response.json()
#         print(f"\n[PLAN RECEIVED] Task: {task_plan['task']}\n")

#         generated_outputs = {}

#         for subtask in task_plan["subtasks"]:
#             step = subtask["step"]
#             description = subtask["description"]
#             agent = subtask["agent"]
#             tool = subtask["tool"]

#             print(f"Step {step}: {description} (Agent: {agent}, Tool: {tool})")

#             subtask["original_task_text"] = user_task

#             if tool == "email_sender" and "text_generation" in generated_outputs:
#                 subtask["email_content"] = generated_outputs["text_generation"]

#             if agent == "WebAgent":
#                 task_payload = {
#                     "jsonrpc": "2.0",
#                     "id": str(uuid.uuid4()),
#                     "method": "execute_subtask",
#                     "params": {
#                          "step": step,
#                         "description": description,
#                         "agent": agent,
#                         "tool": tool,
#                         "original_task_text": user_task
#                     }
#                 }

#                 headers = {
#                         "Accept": "application/json",  # text/event-stream optional
#                         "Content-Type": "application/json"
#                     }


#                 try:
#                     resp = requests.post(WEBAGENT_URL, json=task_payload, headers=headers)
#                     if resp.status_code == 200:
#                         result = resp.json().get("result", {}).get("message", "[No result]")
#                     else:
#                         result = f"[Error] WebAgent failed: {resp.status_code} - {resp.text}"
#                 except Exception as e:
#                     result = f"[Exception] Failed to contact WebAgent MCP: {e}"
#             else:
#                 result = run_tool(tool, context=subtask)

#                 if tool == "text_generation":
#                     if isinstance(result, dict) and "text" in result:
#                         generated_outputs["text_generation"] = result["text"]
#                     elif isinstance(result, str):
#                         generated_outputs["text_generation"] = result

#             print(f"    => Tool result: {result}")

#     except Exception as e:
#         print(f"[ERROR] Failed to parse or execute task plan: {e}")
#         print("Raw response:", response.text)



# if __name__ == "__main__":
#     session_id = "3b5d8bb1-8016-46e3-a83f-057bc495d3a9"
#     initialize_webagent(session_id)
#     user_input = input("Enter your high-level task: ")
#     run_executor(user_input)
